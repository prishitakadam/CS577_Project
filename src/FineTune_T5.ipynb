{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "!pip install bert-extractive-summarizer\n",
        "!pip install -U sentence-transformers\n",
        "!pip install datasets\n",
        "!pip install sentence_transformers\n",
        "!pip install pytorch-lightning\n",
        "!pip install nlp\n",
        "!pip install wandb\n",
        "\n",
        "from datasets import load_dataset\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from transformers import (T5ForConditionalGeneration, T5Tokenizer, AdamW, get_linear_schedule_with_warmup)\n",
        "from nlp import load_metric\n",
        "import time\n",
        "import argparse\n",
        "import logging\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "from nltk.cluster import KMeansClusterer\n",
        "from scipy.spatial import distance_matrix\n",
        "import math\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from summarizer.sbert import SBertSummarizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from torch import cuda\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "!nvidia-smi\n",
        "!wandb login\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "HE45PQ8pfrbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class XMediaData(Dataset):\n",
        "  def __init__(self, split_type, config, dialogue_length, summ_length, tokenizer, extractive_model):\n",
        "    self.data = load_dataset('GEM/xmediasum', split=f'{split_type}')\n",
        "    self.config = config\n",
        "    self.dialogue_length = dialogue_length\n",
        "    self.summ_length = summ_length\n",
        "    self.tokenizer = tokenizer\n",
        "    self.extractive_model = extractive_model\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]\n",
        "\n",
        "  def preprocess_text(self, sentence):\n",
        "    sentence = sentence.replace('\\n','')\n",
        "    sentence = sentence.replace('\\t','')\n",
        "    sentence = sentence.replace('``', '')\n",
        "    return sentence\n",
        "  \n",
        "  def batch_encoding(self, batch):\n",
        "    dialogue = self.preprocess_text(batch['dialogue'])\n",
        "    summary = self.preprocess_text(batch['summary'])\n",
        "\n",
        "    encoded_dialogue = self.tokenizer.batch_encode_plus([dialogue], \n",
        "                                                        max_length=self.dialogue_length, \n",
        "                                                        padding='max_length', \n",
        "                                                        truncation=True, \n",
        "                                                        return_tensors=\"pt\")\n",
        "      \n",
        "    encoded_summary = self.tokenizer.batch_encode_plus( [summary], \n",
        "                                                        max_length=self.summ_length, \n",
        "                                                        padding='max_length', \n",
        "                                                        truncation=True, \n",
        "                                                        return_tensors=\"pt\")\n",
        "  \n",
        "  \n",
        "    dialogue_inp_ids = encoded_dialogue['input_ids'].squeeze()\n",
        "    summary_inp_ids = encoded_summary['input_ids'].squeeze()\n",
        "\n",
        "    dialogue_attention_mask = encoded_dialogue[\"attention_mask\"].squeeze()\n",
        "    summary_attention_mask = encoded_summary[\"attention_mask\"].squeeze()\n",
        "    \n",
        "    return [dialogue_inp_ids, summary_inp_ids, dialogue_attention_mask, summary_attention_mask]\n",
        "\n",
        "  def get_embeddings(self, sentence):\n",
        "    embedding = self.extractive_model.encode([sentence])\n",
        "    return embedding[0]\n",
        "\n",
        "  def centroid_distance(self, sentence):\n",
        "      return distance_matrix([sentence['embeddings']], [sentence['centroid'].tolist()])[0][0]\n",
        "\n",
        "  def extractive_summarizer_data(self, instance):\n",
        "    tokens = nltk.sent_tokenize(instance['dialogue'])\n",
        "    data = pd.DataFrame(tokens)\n",
        "    data.columns = ['sentences']\n",
        "    data['embeddings'] = data['sentences'].apply(self.get_embeddings)\n",
        "\n",
        "    clusters = math.ceil(len(tokens)*0.5)\n",
        "    iterations = 10\n",
        "\n",
        "    X = np.array(data['embeddings'].tolist())\n",
        "    kclusterer = KMeansClusterer( clusters, \n",
        "                                  distance=nltk.cluster.util.cosine_distance,\n",
        "                                  repeats=iterations,\n",
        "                                  avoid_empty_clusters=True)\n",
        "    \n",
        "    \n",
        "    assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
        "\n",
        "    data['cluster'] = pd.Series(assigned_clusters, index=data.index)\n",
        "    data['centroid'] = data['cluster'].apply(lambda x: kclusterer.means()[x])\n",
        "    data['centroid_distance'] = data.apply(self.centroid_distance, axis=1)\n",
        "\n",
        "    extractive_summary = ' '.join(data.sort_values('centroid_distance', ascending = True).groupby('cluster').head(1).sort_index()['sentences'].tolist())\n",
        "    instance['dialogue'] = extractive_summary\n",
        "\n",
        "    return instance\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    instance = self.data[idx]\n",
        "    if self.config == 'Extractive':\n",
        "        instance['dialogue'] = self.extractive_model(self.data[idx]['dialogue'], ratio=0.5)\n",
        "    dialogue_inp_ids, summary_inp_ids, dialogue_attention_mask, summary_attention_mask = self.batch_encoding(instance)\n",
        "    return {\"dialogue_input_ids\": dialogue_inp_ids.to(dtype=torch.long), \"dialogue_attention_mask\": dialogue_attention_mask.to(dtype=torch.long), \"summary_input_ids\": summary_inp_ids.to(dtype=torch.long), \"summary_attention_mask\": summary_attention_mask.to(dtype=torch.long)}"
      ],
      "metadata": {
        "id": "Is88XoMTfju4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65u9xESwe_ML"
      },
      "outputs": [],
      "source": [
        "class Summarizer:\n",
        "    def __init__(self):\n",
        "        # Specifying the project for wandb logging\n",
        "        self.device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "        print(f'Device : {self.device}')\n",
        "        wandb.init(project=\"abstractive_dialogue_summarizer\")\n",
        "\n",
        "        self.config, self.train_parameters, self.validation_parameters = self.get_config()\n",
        "\n",
        "        torch.manual_seed(self.config.SEED)\n",
        "        np.random.seed(self.config.SEED)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "\n",
        "        # self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "        # self.extractive_model = SBertSummarizer('all-MiniLM-L6-v2')\n",
        "\n",
        "        # if self.config.HYPER_PARAMETER_TUNING:\n",
        "        #   self.train_data = XMediaData('train[:20%]', self.config.SUMMARY_TYPE, self.config.MAX_LEN, self.config.SUMMARY_LEN, self.tokenizer, self.extractive_model)\n",
        "        #   self.val_data = XMediaData('validation[:20%]', self.config.SUMMARY_TYPE, self.config.MAX_LEN, self.config.SUMMARY_LEN, self.tokenizer, self.extractive_model)\n",
        "        #   print(\"Train Samples : \" + str(len(self.train_data)))\n",
        "        #   print(\"Val Samples : \" + str(len(self.val_data)))\n",
        "        # else:\n",
        "        #   self.train_data = XMediaData('train', self.config.SUMMARY_TYPE, self.config.MAX_LEN, self.config.SUMMARY_LEN, self.tokenizer, self.extractive_model)\n",
        "        #   self.val_data = XMediaData('validation', self.config.SUMMARY_TYPE, self.config.MAX_LEN, self.config.SUMMARY_LEN, self.tokenizer, self.extractive_model)\n",
        "\n",
        "        # self.train_batch = DataLoader(self.train_data, **self.train_parameters)\n",
        "        # self.val_batch = DataLoader(self.val_data, **self.validation_parameters)\n",
        "\n",
        "        # self.abstractive_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "        # self.abstractive_model = self.abstractive_model.to(self.device)\n",
        "\n",
        "        # self.optimizer = torch.optim.Adam(params=self.abstractive_model.parameters(), lr=self.config.LEARNING_RATE)\n",
        "\n",
        "        # wandb.watch(self.abstractive_model, log=\"all\")\n",
        "\n",
        "        if self.config.HYPER_PARAMETER_TUNING:\n",
        "          for lr in self.config.LR_TUNING:\n",
        "            print(f'---------------------------------- LR : {lr} ----------------------------------')\n",
        "            self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "            self.extractive_model = SBertSummarizer('all-MiniLM-L6-v2')\n",
        "            self.abstractive_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "            self.abstractive_model = self.abstractive_model.to(self.device)\n",
        "            self.optimizer = torch.optim.Adam(params=self.abstractive_model.parameters(), lr=lr)\n",
        "            self.train_data = XMediaData('train[:20%]', self.config.SUMMARY_TYPE, self.config.MAX_LEN, self.config.SUMMARY_LEN, self.tokenizer, self.extractive_model)\n",
        "            self.val_data = XMediaData('validation[:20%]', self.config.SUMMARY_TYPE, self.config.MAX_LEN, self.config.SUMMARY_LEN, self.tokenizer, self.extractive_model)\n",
        "            print(\"Train Samples : \" + str(len(self.train_data)))\n",
        "            print(\"Val Samples : \" + str(len(self.val_data)))\n",
        "            self.train_batch = DataLoader(self.train_data, **self.train_parameters)\n",
        "            self.val_batch = DataLoader(self.val_data, **self.validation_parameters)\n",
        "            wandb.watch(self.abstractive_model, log=\"all\")\n",
        "            self.train()\n",
        "            self.validation()\n",
        "            print(f'--------------------------------------------------------------------------------')\n",
        "\n",
        "        else:\n",
        "          self.tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "          self.extractive_model = SBertSummarizer('all-MiniLM-L6-v2')\n",
        "          self.abstractive_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "          self.abstractive_model = self.abstractive_model.to(self.device)\n",
        "          self.train_data = XMediaData('train', self.config.SUMMARY_TYPE, self.config.MAX_LEN, self.config.SUMMARY_LEN, self.tokenizer, self.extractive_model)\n",
        "          self.val_data = XMediaData('validation', self.config.SUMMARY_TYPE, self.config.MAX_LEN, self.config.SUMMARY_LEN, self.tokenizer, self.extractive_model)\n",
        "          self.train_batch = DataLoader(self.train_data, **self.train_parameters)\n",
        "          self.val_batch = DataLoader(self.val_data, **self.validation_parameters)\n",
        "          self.optimizer = torch.optim.Adam(params=self.abstractive_model.parameters(), lr=self.config.LEARNING_RATE)\n",
        "          wandb.watch(self.abstractive_model, log=\"all\")\n",
        "          self.train()\n",
        "          self.validation()\n",
        "\n",
        "    def get_config(self):\n",
        "        config = wandb.config\n",
        "        config.TRAIN_BATCH_SIZE = 2\n",
        "        config.VALID_BATCH_SIZE = 2\n",
        "        config.TRAIN_EPOCHS = 2\n",
        "        config.VAL_EPOCHS = 1 \n",
        "        config.HYPER_PARAMETER_TUNING = False\n",
        "        config.LEARNING_RATE = 3e-5\n",
        "        # config.LEARNING_RATE = 1e-4\n",
        "        config.LR_TUNING = [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n",
        "        config.SEED = 42\n",
        "        config.MAX_LEN = 512\n",
        "        config.SUMMARY_LEN = 64\n",
        "        config.NO_REPEAT_N_GRAMS = 5\n",
        "        config.SUMMARY_TYPE = 'Abstractive'\n",
        "\n",
        "        train_parameters = {'batch_size': config.TRAIN_BATCH_SIZE,\n",
        "                        'shuffle': True,\n",
        "                        'num_workers': 0}\n",
        "\n",
        "        validation_parameters = {  'batch_size': config.VALID_BATCH_SIZE,\n",
        "                        'shuffle': False,\n",
        "                        'num_workers': 0}\n",
        "        \n",
        "        return config, train_parameters, validation_parameters\n",
        "    \n",
        "    def train(self):\n",
        "        for epoch in range(self.config.TRAIN_EPOCHS):\n",
        "            self.finetune(epoch)\n",
        "\n",
        "        if self.config.HYPER_PARAMETER_TUNING == False:\n",
        "          model_name = f'{self.config.SUMMARY_TYPE}_summarizer_small.pt'\n",
        "          path = f\"/content/gdrive/My Drive/{model_name}\" \n",
        "          torch.save(self.abstractive_model.state_dict(), path)\n",
        "    \n",
        "    def finetune(self, epoch):\n",
        "        self.abstractive_model.train()\n",
        "        total_loss  = 0\n",
        "        batch = 0\n",
        "        for i,instance in enumerate(self.train_batch, 0):\n",
        "            \n",
        "            summary_inp_ids = instance['summary_input_ids'].to(self.device, dtype=torch.long)\n",
        "            summ_ids = summary_inp_ids[:, :-1].contiguous()\n",
        "\n",
        "            labels = summary_inp_ids[:, 1:].clone().detach()\n",
        "            labels[summary_inp_ids[:, 1:] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "            ids = instance['dialogue_input_ids'].to(self.device, dtype=torch.long)\n",
        "            mask = instance['dialogue_attention_mask'].to(self.device, dtype=torch.long)\n",
        "\n",
        "            output = self.abstractive_model(input_ids=ids, attention_mask=mask, decoder_input_ids=summ_ids, labels=labels)\n",
        "            loss = output[0]\n",
        "            \n",
        "            if i%10 == 0:\n",
        "                wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "            if i%500==0:\n",
        "                print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "            \n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            batch += len(self.train_batch)\n",
        "          \n",
        "        print(f\"Epoch {epoch + 1} Loss: {total_loss/batch}\")\n",
        "        \n",
        "    \n",
        "    def validation(self):\n",
        "        for epoch in range(self.config.VAL_EPOCHS):\n",
        "            predicted_summ, actual_summ = self.validate_model(epoch)\n",
        "            \n",
        "            df = pd.DataFrame({'Generated Text':predicted_summ, 'Actual Text':actual_summ})\n",
        "            df.to_csv(f'/content/gdrive/My Drive/{self.config.SUMMARY_TYPE}_{epoch}_predictions_t5_small_ex_final.csv')\n",
        "    \n",
        "    def validate_model(self, epoch):\n",
        "        self.abstractive_model.eval()\n",
        "        predicted_summ, actual_summ = [], []\n",
        "        with torch.no_grad():\n",
        "          for i,instance in enumerate(self.val_batch, 0):\n",
        "              summary_inp_ids = instance['summary_input_ids'].to(self.device, dtype = torch.long)\n",
        "\n",
        "              ids = instance['dialogue_input_ids'].to(self.device, dtype = torch.long)\n",
        "              mask = instance['dialogue_attention_mask'].to(self.device, dtype = torch.long)\n",
        "\n",
        "              generated = self.abstractive_model.generate(input_ids=ids,\n",
        "                                                              attention_mask=mask, \n",
        "                                                              max_length=64, \n",
        "                                                              num_beams=2,\n",
        "                                                              repetition_penalty=2.5, \n",
        "                                                              length_penalty=1.0, \n",
        "                                                              early_stopping=True)\n",
        "\n",
        "              predictions = [self.tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_id in generated]\n",
        "              actual = [self.tokenizer.decode(summ, skip_special_tokens=True, clean_up_tokenization_spaces=True)for summ in summary_inp_ids]\n",
        "\n",
        "\n",
        "              if i%100==0:\n",
        "                  print(f'Completed {i}')\n",
        "              \n",
        "\n",
        "              predicted_summ.extend(predictions)\n",
        "              actual_summ.extend(actual)\n",
        "\n",
        "        return predicted_summ, actual_summ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Summarizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computing Rouge Scores"
      ],
      "metadata": {
        "id": "9JbR0gXgfQlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generated Text':predicted_summ, 'Actual Text'"
      ],
      "metadata": {
        "id": "jJtm3BjkfUdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install transformers[sentencepiece]\n",
        "!pip install tqdm\n",
        "!pip install rouge"
      ],
      "metadata": {
        "id": "j3rfRqZo5eVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "from rouge import Rouge"
      ],
      "metadata": {
        "id": "TSi8qs5w5h_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = load_dataset('GEM/xmediasum', split='validation')\n",
        "actual_summaries = []\n",
        "for val in val_data:\n",
        "  actual_summaries.append(val['summary'])\n",
        "print(len(actual_summaries))\n",
        "actual_summaries[0]"
      ],
      "metadata": {
        "id": "ZouAgjqS5btX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetune_data = pd.read_csv('/content/Extractive_0_predictions_t5_small_ex_final.csv')\n",
        "summaries = finetune_data[['Generated Text']]\n",
        "generated_summaries = summaries.values.tolist()\n",
        "finetune_summaries = []\n",
        "for sum in generated_summaries:\n",
        "  finetune_summaries.append(sum[0])"
      ],
      "metadata": {
        "id": "qNJjlxgh61mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_single_rouge_scores(idx):\n",
        "  rouge = Rouge()\n",
        "  actual_summary = actual_summaries[idx]\n",
        "  actual_summary = actual_summary.encode('ascii', 'ignore').decode('ascii').replace('Summary: ', '')\n",
        "  generated_sumamry = finetune_summaries[idx]\n",
        "  return rouge.get_scores(generated_sumamry, actual_summary)[0]"
      ],
      "metadata": {
        "id": "iIq0Gc5qeTzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(rouge, param):\n",
        "  total = 0\n",
        "  for i in tqdm_notebook(range(len(actual_summaries)), desc=f'{param}'):\n",
        "    total += get_single_rouge_scores(i)[rouge][param]\n",
        "  return total/len(actual_summaries)"
      ],
      "metadata": {
        "id": "UgC_XzFIfQBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Rouge-1 Scores')\n",
        "print(f\"r : {get_score('rouge-1', 'r')}\")\n",
        "print(f\"p : {get_score('rouge-1', 'p')}\")\n",
        "print(f\"f : {get_score('rouge-1', 'f')}\")\n",
        "\n",
        "print('\\nRouge-2 Scores')\n",
        "print(f\"r : {get_score('rouge-2', 'r')}\")\n",
        "print(f\"p : {get_score('rouge-2', 'p')}\")\n",
        "print(f\"f : {get_score('rouge-2', 'f')}\")\n",
        "\n",
        "print('\\nRouge-l Scores')\n",
        "print(f\"r : {get_score('rouge-l', 'r')}\")\n",
        "print(f\"p : {get_score('rouge-l', 'p')}\")\n",
        "print(f\"f : {get_score('rouge-l', 'f')}\")"
      ],
      "metadata": {
        "id": "rCj0nAsB6FTu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}