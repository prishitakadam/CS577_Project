{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "53Ps_crVXovp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZoE5iTKiTEK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install sentencepiece\n",
        "!pip install rouge\n",
        "!pip install wandb\n",
        "!pip install bert-extractive-summarizer\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PFEFknTpVrt"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import time\n",
        "from torch import cuda\n",
        "import csv\n",
        "from rouge import Rouge\n",
        "import wandb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from summarizer.sbert import SBertSummarizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yZBZer325GO"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'Device : {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWl-n0oI8_k_"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okY-i6nOn-b1"
      },
      "outputs": [],
      "source": [
        "class XMediaData(Dataset):\n",
        "  def __init__(self, split_type, extracive, ratio):\n",
        "    self.data = load_dataset('GEM/xmediasum', split=split_type)\n",
        "    self.extractive = extracive\n",
        "    self.ratio = ratio\n",
        "    if self.extractive:\n",
        "      self.extractive_model = SBertSummarizer('all-MiniLM-L6-v2')\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.extractive:\n",
        "      instance = self.data[idx]\n",
        "      instance['dialogue'] = self.extractive_model(self.data[idx]['dialogue'], ratio=self.ratio)\n",
        "      return (f\"Summarize: {instance['dialogue']}\", f\"Summary: {self.data[idx]['summary']}\")\n",
        "    else:\n",
        "      return (f\"Summarize: {self.data[idx]['dialogue']}\", f\"Summary: {self.data[idx]['summary']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUFPh9NkoYmD"
      },
      "outputs": [],
      "source": [
        "extractive = True\n",
        "ratio = 0.75\n",
        "train_data = XMediaData('train', extractive, ratio)\n",
        "val_data = XMediaData('validation', extractive, ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlaBNCThpscx"
      },
      "outputs": [],
      "source": [
        "print(len(train_data))\n",
        "print(len(val_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTfUI270uOlV"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"abstractive_dialogue_summarizer\")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "input_ids = tokenizer.batch_encode_plus([train_data[ex][0] for ex in tqdm_notebook(range(len(train_data)), desc='input_ids')], max_length=512, truncation=True, padding='longest', return_tensors='pt').to(device)\n",
        "output_ids = tokenizer.batch_encode_plus([train_data[ex][1] for ex in tqdm_notebook(range(len(train_data)), desc='output_ids')], max_length=512, truncation=True, padding='longest', return_tensors='pt').to(device)\n",
        "\n",
        "# train the model on the few-shot examples\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4Ri_K4cAKC4"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm_notebook(range(3), desc='Epoch'):\n",
        "    total_loss = 0.0\n",
        "    for i in tqdm_notebook(range(len(train_data)), desc= 'Trained'):\n",
        "        input_seq = input_ids['input_ids'][i].unsqueeze(0).to(device)\n",
        "        output_seq = output_ids['input_ids'][i].unsqueeze(0).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # generate summary\n",
        "        outputs = model(input_ids=input_seq, labels=output_seq)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        wandb.log({\"Training Loss\": loss.item()})\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} Loss: {total_loss/len(train_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbCl1gaPw9SD"
      },
      "outputs": [],
      "source": [
        "summaries = {}\n",
        "for i in tqdm_notebook(range(len(val_data)), desc = 'Generated Summaries'):\n",
        "  input_ids = tokenizer.encode_plus(val_data[i], max_length=512, truncation=True, padding='longest', return_tensors='pt').to(device)\n",
        "  summary_ids = model.generate(input_ids=input_ids['input_ids'], num_beams=4, max_length=128, early_stopping=True).to(device)\n",
        "  summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "  summaries[val_data[i]] = summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIVcO-M2xlzg"
      },
      "outputs": [],
      "source": [
        "file = open('few_shot_extractive.txt', 'w')\n",
        "for k,v in summaries.items():\n",
        "    file.write(v.encode('ascii', 'ignore').decode('ascii').replace('Summary: ', ''))\n",
        "    file.write('\\n')\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQHiwcoCCRQN"
      },
      "outputs": [],
      "source": [
        "generated_summaries = []\n",
        "for k,v in summaries.items():\n",
        "  generated_summaries.append(v.encode('ascii', 'ignore').decode('ascii').replace('Summary: ', ''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-1tebdvzFpE"
      },
      "outputs": [],
      "source": [
        "def get_single_rouge_scores(idx):\n",
        "  rouge = Rouge()\n",
        "  actual_summary = val_data[idx][1]\n",
        "  actual_summary = actual_summary.encode('ascii', 'ignore').decode('ascii').replace('Summary: ', '')\n",
        "  generated_sumamry = generated_summaries[idx]\n",
        "  return rouge.get_scores(generated_sumamry, actual_summary)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbnRXjt8Cl8s"
      },
      "outputs": [],
      "source": [
        "def get_score(rouge, param):\n",
        "  total = 0\n",
        "  for i in tqdm_notebook(range(len(generated_summaries)), desc=f'{param}'):\n",
        "    total += get_single_rouge_scores(i)[rouge][param]\n",
        "  return total/len(generated_summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGweiwuVE1pI"
      },
      "outputs": [],
      "source": [
        "print('Rouge-1 Scores')\n",
        "print(f\"r : {get_score('rouge-1', 'r')}\")\n",
        "print(f\"p : {get_score('rouge-1', 'p')}\")\n",
        "print(f\"f : {get_score('rouge-1', 'f')}\")\n",
        "\n",
        "print('\\nRouge-2 Scores')\n",
        "print(f\"r : {get_score('rouge-2', 'r')}\")\n",
        "print(f\"p : {get_score('rouge-2', 'p')}\")\n",
        "print(f\"f : {get_score('rouge-2', 'f')}\")\n",
        "\n",
        "print('\\nRouge-l Scores')\n",
        "print(f\"r : {get_score('rouge-l', 'r')}\")\n",
        "print(f\"p : {get_score('rouge-l', 'p')}\")\n",
        "print(f\"f : {get_score('rouge-l', 'f')}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}